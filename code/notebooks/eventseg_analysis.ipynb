{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the event segmentation analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import brainiak.eventseg.event\n",
    "import hypertools as hyp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "import pickle\n",
    "\n",
    "def score_model(mcorr, model, k, s):\n",
    "    i1, i2 = np.where(np.round(model.segments_[0])==1)\n",
    "    w = np.zeros_like(model.segments_[0])\n",
    "    w[i1,i2] = 1\n",
    "    w = np.dot(w, w.T).astype(bool)\n",
    "    return mcorr[w].mean()/mcorr[~w].mean() - k/s\n",
    "    \n",
    "def reduce_model(m, ev):\n",
    "    \"\"\"Reduce a model based on event labels\"\"\"\n",
    "    w = (np.round(ev.segments_[0])==1).astype(bool)\n",
    "    return np.array([m[wi, :].mean(0) for wi in w.T])\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../../data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_model, recall_models = np.load(datadir+'models_t100_v50_r10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -10.128918054405212\n",
      "3 -17.00797935606088\n",
      "4 -22.527770602626493\n",
      "5 -37.047163823757685\n",
      "6 -52.432859456617436\n",
      "7 -59.15419823934286\n",
      "8 -86.04022228160703\n",
      "9 -133.36130785912854\n",
      "10 -198.28786864314063\n",
      "11 -295.170031770841\n",
      "12 -5489.809080387881\n",
      "13 2863.52260266772\n",
      "14 279.9076678506955\n",
      "15 189.32035211796736\n",
      "16 155.6611987504374\n",
      "17 131.80299966583988\n",
      "18 115.39873831147254\n",
      "19 103.18510498831188\n",
      "20 93.66781576702915\n",
      "21 88.80190057306737\n",
      "22 82.19720938923747\n",
      "23 74.12309240457814\n",
      "24 69.14241210535243\n",
      "25 69.81938950698537\n",
      "26 65.02740569926117\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c7f466647f7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrainiak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meventseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEventSegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# score model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/brainiak/eventseg/event.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 logprob = self._logprob_obs(X[i],\n\u001b[1;32m    157\u001b[0m                                             mean_pat, iteration_var)\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mlog_gamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mll_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;31m# If log-likelihood has started decreasing, undo last step and stop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/brainiak/eventseg/event.py\u001b[0m in \u001b[0;36m_forward_backward\u001b[0;34m(self, logprob)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 log_alpha[i, :] = self._log(np.exp(log_alpha[i - 1, :])\n\u001b[0;32m--> 276\u001b[0;31m                                             .dot(P)) + logprob[i, :]\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mlog_scale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogaddexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_alpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/brainiak/eventseg/event.py\u001b[0m in \u001b[0;36m_log\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mxshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ks = list(range(2, 50))\n",
    "maxk = []\n",
    "mcorr = np.corrcoef(video_model)\n",
    "s = 10\n",
    "cs = []\n",
    "\n",
    "for k in ks:\n",
    "    \n",
    "    # fit model\n",
    "    ev = brainiak.eventseg.event.EventSegment(k)\n",
    "    ev.fit(video_model)\n",
    "    \n",
    "    # score model\n",
    "    c = score_model(mcorr, ev, k, s)\n",
    "    cs.append(c)\n",
    "    print(k, c)\n",
    "    \n",
    "print(ks[np.argmax(cs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit event segmentation model to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = brainiak.eventseg.event.EventSegment(34)\n",
    "ev.fit(video_model)\n",
    "video_events = reduce_model(video_model, ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/video_eventseg_model', 'wb') as f:\n",
    "#     pickle.dump(ev, f)\n",
    "# np.save('../data/video_events', video_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get video event times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_event_times = []\n",
    "for s in ev.segments_[0].T:\n",
    "    tp = np.where(np.round(s)==1)[0]\n",
    "    video_event_times.append((tp[0], tp[-1]))\n",
    "np.save(datadir+'video_event_times', video_event_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit event segmentation model to recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8\n",
      "1 14\n",
      "2 11\n",
      "3 9\n",
      "4 14\n",
      "5 10\n",
      "6 17\n",
      "7 17\n",
      "8 10\n",
      "9 20\n",
      "10 19\n",
      "11 25\n",
      "12 27\n",
      "13 14\n",
      "14 10\n",
      "15 14\n",
      "16 23\n"
     ]
    }
   ],
   "source": [
    "# ks = list(range(2, 30))\n",
    "# maxk = []\n",
    "# for i, sub in enumerate(recall_models):\n",
    "#     mcorr = np.corrcoef(sub)\n",
    "#     cs = []\n",
    "#     for k in ks:\n",
    "#         ev = brainiak.eventseg.event.EventSegment(k)\n",
    "#         ev.fit(sub)\n",
    "#         i1, i2 = np.where(np.round(ev.segments_[0])==1)\n",
    "#         w = np.zeros_like(ev.segments_[0])\n",
    "#         w[i1,i2] = 1\n",
    "#         w = np.dot(w, w.T).astype(bool)\n",
    "#         c = mcorr[w].mean()/mcorr[~w].mean() - k/50\n",
    "#         cs.append(c)\n",
    "#     m = ks[np.argmax(cs)]\n",
    "#     maxk.append(m)\n",
    "#     print(i, m)\n",
    "maxk = np.array([8, 14, 11, 9, 14, 10, 17, 17, 10, 20, 19, 25, 27, 14, 10, 14, 23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model to recall using best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_events = []\n",
    "recall_event_times = []\n",
    "recall_eventseg_models = []\n",
    "for i, k in enumerate(maxk):\n",
    "    ev = brainiak.eventseg.event.EventSegment(k)\n",
    "    ev.fit(recall_models[i])\n",
    "    m = reduce_model(recall_models[i], ev)\n",
    "    recall_events.append(m)\n",
    "    recall_times = []\n",
    "    for s in ev.segments_[0].T:\n",
    "        tp = np.where(np.round(s)==1)[0]\n",
    "        recall_times.append((tp[0], tp[-1]))\n",
    "    recall_event_times.append(recall_times)\n",
    "    recall_eventseg_models.append(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create average recall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = np.array([np.argmax(1 - cdist(video_events, r, 'correlation'), 0) for r in recall_events])\n",
    "avg_recalls = [[] for _ in video_events]\n",
    "for match, r in zip(matches, recall_events):\n",
    "    for i, m in enumerate(match):\n",
    "        avg_recalls[m].append(r[i,:])\n",
    "avg_recall_events = np.array(list(map(lambda r: np.mean(r, 0) if len(r)>0 else np.zeros((100,)), avg_recalls)))\n",
    "# avg_recall_events = np.array([a.reshape(100,) for a in avg_recall_events if a.shape==(100,)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 2D embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "embeddings = hyp.reduce(recall_events+[video_events]+[avg_recall_events], reduce='UMAP', ndims=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(datadir+'avg_recall_events', avg_recall_events)\n",
    "# np.save(datadir+'embeddings', [embeddings[:-2], embeddings[-2], embeddings[:-1]])\n",
    "# np.save(datadir+'labels', matches)\n",
    "# np.save(datadir+'recall_events', recall_events)\n",
    "# np.save(datadir+'recall_event_times', recall_event_times)\n",
    "# with open(datadir+'recall_eventseg_models', 'wb') as f:\n",
    "#     pickle.dump(recall_eventseg_models, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
