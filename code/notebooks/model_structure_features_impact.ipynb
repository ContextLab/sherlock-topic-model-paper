{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T20:28:26.578000Z",
     "start_time": "2018-08-26T20:28:26.555884Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hypertools as hyp\n",
    "import quail\n",
    "from scipy.stats import pearsonr as corr\n",
    "from scipy.signal import resample\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('poster')\n",
    "sns.set_style('ticks')\n",
    "plt.rc('figure', figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T17:36:55.534730Z",
     "start_time": "2018-08-26T17:36:55.531741Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawdir = '../../data/raw/'\n",
    "datadir = '../../data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T17:36:56.306512Z",
     "start_time": "2018-08-26T17:36:56.123719Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in raw annotation file\n",
    "movie_annotations = pd.read_excel(rawdir+'Sherlock_Segments_1000_NN_2017.xlsx')\n",
    "movie_annotations['Scene Segments'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T17:36:58.093886Z",
     "start_time": "2018-08-26T17:36:58.087905Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "ntopics = 100\n",
    "m_wsize = 50\n",
    "\n",
    "# vectorizer parameters\n",
    "vectorizer = {\n",
    "    'model' : 'CountVectorizer', \n",
    "    'params' : {\n",
    "        'stop_words' : 'english'\n",
    "    }\n",
    "}\n",
    "\n",
    "# topic model parameters\n",
    "semantic = {\n",
    "    'model' : 'LatentDirichletAllocation', \n",
    "    'params' : {\n",
    "        'n_components' : ntopics,\n",
    "        'learning_method' : 'batch',\n",
    "        'random_state' : 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T17:37:03.068380Z",
     "start_time": "2018-08-26T17:37:03.036076Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train a topic model on text samples from the scene annotations\n",
    "def model_movie(movie_df, w_size, vec_params, sem_params):\n",
    "\n",
    "    # create list of text samples from annotations\n",
    "    movie_text = movie_df.apply(lambda x: ','.join(x.fillna('')), axis=1).values.tolist()\n",
    "    \n",
    "    # create sliding window of text samples\n",
    "    movie_windows = []\n",
    "    for idx, sentence in enumerate(movie_text):\n",
    "        movie_windows.append(','.join(movie_text[idx:idx+w_size]))\n",
    "\n",
    "    # vectorizer and topic model parameters\n",
    "    vectorizer = vec_params\n",
    "    semantic = sem_params\n",
    "\n",
    "    # use hypertools to create movie model\n",
    "    movie_model = hyp.tools.format_data(movie_windows, vectorizer=vec_params, semantic=sem_params, corpus=movie_windows)[0]\n",
    "\n",
    "    # scene description are by shot, not TR, so stretch the model to be in TRs\n",
    "    ranges =[[d['Start Time (TRs, 1.5s)'],d['End Time (TRs, 1.5s)']] for i, d in movie_annotations.iterrows()] \n",
    "    expanded = []\n",
    "    for i in range(1976):\n",
    "        try:\n",
    "            idx = np.where([i>=r[0] and i<=r[1] for r in ranges])[0][0]\n",
    "            expanded.append(movie_model[idx, :])\n",
    "        except:\n",
    "            expanded.append(movie_model[0, :])\n",
    "    \n",
    "    return np.array(expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T17:37:07.811448Z",
     "start_time": "2018-08-26T17:37:07.806401Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop a single feature from the model\n",
    "def drop_feature(df, feature):\n",
    "    return df.drop(feature, axis=1)\n",
    "\n",
    "# computes correlation between movie models\n",
    "def compare_m_models(model1, model2):\n",
    "    return corr(pd.DataFrame(model1).T.corr().values.ravel(), pd.DataFrame(model2).T.corr().values.ravel())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## which features are important to movie model structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T17:37:09.865168Z",
     "start_time": "2018-08-26T17:37:09.859768Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# isolate features used in model\n",
    "features_df = movie_annotations.loc[:,'Scene Details - A Level ':'Words on Screen ']\n",
    "features_df.columns = ['Narrative Details', 'Indoor vs Outdoor', 'Characters on Screen', 'Character in Focus', 'Character Speaking', 'Location', 'Camera Angle', 'Music Presence', 'Text on Screen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T17:37:11.022752Z",
     "start_time": "2018-08-26T17:37:10.872344Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in full movie model\n",
    "full_movie_model = np.load(datadir+'models_t100_v50_r10_resampled.npy')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T17:40:04.183755Z",
     "start_time": "2018-08-26T17:37:11.951928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dropping Narrative Details\n",
      "computing movie model\n",
      "model correlation is 0.816999416619916\n",
      "\n",
      "dropping Indoor vs Outdoor\n",
      "computing movie model\n",
      "model correlation is 0.8766734235574367\n",
      "\n",
      "dropping Characters on Screen\n",
      "computing movie model\n",
      "model correlation is 0.8852409813813537\n",
      "\n",
      "dropping Character in Focus\n",
      "computing movie model\n",
      "model correlation is 0.9471895100684966\n",
      "\n",
      "dropping Character Speaking\n",
      "computing movie model\n",
      "model correlation is 0.8748901536160689\n",
      "\n",
      "dropping Location\n",
      "computing movie model\n",
      "model correlation is 0.906258567201294\n",
      "\n",
      "dropping Camera Angle\n",
      "computing movie model\n",
      "model correlation is 0.8927190384602313\n",
      "\n",
      "dropping Music Presence\n",
      "computing movie model\n",
      "model correlation is 0.9288485515393562\n",
      "\n",
      "dropping Text on Screen\n",
      "computing movie model\n",
      "model correlation is 0.999492553995031\n"
     ]
    }
   ],
   "source": [
    "dropfeat_corr = {}\n",
    "\n",
    "# iteratively leave out one feature from the model \n",
    "for feat in features_df.columns:\n",
    "    print('\\ndropping '+str(feat))\n",
    "    partial_df = drop_feature(features_df,feat)\n",
    "    \n",
    "    # compute partial movie model\n",
    "    print('computing movie model')\n",
    "    partial_movie_model = model_movie(partial_df, m_wsize, vectorizer, semantic)\n",
    "    \n",
    "    # correlate to full model\n",
    "    model_corr = compare_m_models(partial_movie_model, full_movie_model)\n",
    "    print('model correlation is '+ str(model_corr))\n",
    "    dropfeat_corr[feat] = model_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T21:24:24.478050Z",
     "start_time": "2018-08-26T21:24:24.474544Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export data to plot\n",
    "np.save(datadir+'dropfeat_models/dropfeat_m_model_impact', dropfeat_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T00:29:17.413968Z",
     "start_time": "2018-08-27T00:29:17.410082Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot correlation with full model\n",
    "# sns.set_palette('muted')\n",
    "\n",
    "# series_ord = pd.Series(dropfeat_corr).sort_values()\n",
    "# series_ord.plot(kind='bar', ylim=[0,1])\n",
    "# plt.ylabel('Correlation with full model', labelpad=15)\n",
    "# plt.xlabel('Feature removed', labelpad=20)\n",
    "\n",
    "# for idx, corr in enumerate(series_ord.values):\n",
    "#     plt.text(idx-.1, 0.42, '%.5f'%corr, rotation=90)\n",
    "    \n",
    "# plt.savefig('../../paper/figs/5.1_dropfeat_m_model_corr.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
