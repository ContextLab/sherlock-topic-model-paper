{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the event segmentation analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import brainiak.eventseg.event\n",
    "import hypertools as hyp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "import pickle\n",
    "\n",
    "def score_model(model, k, s):\n",
    "    i1, i2 = np.where(np.round(model.segments_[0])==1)\n",
    "    w = np.zeros_like(model.segments_[0])\n",
    "    w[i1,i2] = 1\n",
    "    w = np.dot(w, w.T).astype(bool)\n",
    "    return mcorr[w].mean()/mcorr[~w].mean() - k/s\n",
    "    \n",
    "def reduce_model(m, ev):\n",
    "    \"\"\"Reduce a model based on event labels\"\"\"\n",
    "    w = (np.round(ev.segments_[0])==1).astype(bool)\n",
    "    return np.array([m[wi, :].mean(0) for wi in w.T])\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../../data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_model, recall_models = np.load(datadir+'models_t100_v50_r10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = list(range(2, 50))\n",
    "maxk = []\n",
    "mcorr = np.corrcoef(video_model)\n",
    "for k in ks:\n",
    "    \n",
    "    # fit model\n",
    "    ev = brainiak.eventseg.event.EventSegment(k)\n",
    "    ev.fit(sub)\n",
    "    \n",
    "    # score model\n",
    "    c = score_model(mcorr, ev, k, s)\n",
    "    cs.append(c)\n",
    "    \n",
    "print(ks[np.argmax(cs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit event segmentation model to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = brainiak.eventseg.event.EventSegment(34)\n",
    "ev.fit(video_model)\n",
    "video_events = reduce_model(video_model, ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/video_eventseg_model', 'wb') as f:\n",
    "#     pickle.dump(ev, f)\n",
    "# np.save('../data/video_events', video_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get video event times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_event_times = []\n",
    "for s in ev.segments_[0].T:\n",
    "    tp = np.where(np.round(s)==1)[0]\n",
    "    video_event_times.append((tp[0], tp[-1]))\n",
    "np.save(datadir+'video_event_times', video_event_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit event segmentation model to recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8\n",
      "1 14\n",
      "2 11\n",
      "3 9\n",
      "4 14\n",
      "5 10\n",
      "6 17\n",
      "7 17\n",
      "8 10\n",
      "9 20\n",
      "10 19\n",
      "11 25\n",
      "12 27\n",
      "13 14\n",
      "14 10\n",
      "15 14\n",
      "16 23\n"
     ]
    }
   ],
   "source": [
    "# ks = list(range(2, 30))\n",
    "# maxk = []\n",
    "# for i, sub in enumerate(recall_models):\n",
    "#     mcorr = np.corrcoef(sub)\n",
    "#     cs = []\n",
    "#     for k in ks:\n",
    "#         ev = brainiak.eventseg.event.EventSegment(k)\n",
    "#         ev.fit(sub)\n",
    "#         i1, i2 = np.where(np.round(ev.segments_[0])==1)\n",
    "#         w = np.zeros_like(ev.segments_[0])\n",
    "#         w[i1,i2] = 1\n",
    "#         w = np.dot(w, w.T).astype(bool)\n",
    "#         c = mcorr[w].mean()/mcorr[~w].mean() - k/50\n",
    "#         cs.append(c)\n",
    "#     m = ks[np.argmax(cs)]\n",
    "#     maxk.append(m)\n",
    "#     print(i, m)\n",
    "maxk = np.array([8, 14, 11, 9, 14, 10, 17, 17, 10, 20, 19, 25, 27, 14, 10, 14, 23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model to recall using best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_events = []\n",
    "recall_event_times = []\n",
    "recall_eventseg_models = []\n",
    "for i, k in enumerate(maxk):\n",
    "    ev = brainiak.eventseg.event.EventSegment(k)\n",
    "    ev.fit(recall_models[i])\n",
    "    m = reduce_model(recall_models[i], ev)\n",
    "    recall_events.append(m)\n",
    "    recall_times = []\n",
    "    for s in ev.segments_[0].T:\n",
    "        tp = np.where(np.round(s)==1)[0]\n",
    "        recall_times.append((tp[0], tp[-1]))\n",
    "    recall_event_times.append(recall_times)\n",
    "    recall_eventseg_models.append(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create average recall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = np.array([np.argmax(1 - cdist(video_events, r, 'correlation'), 0) for r in recall_events])\n",
    "avg_recalls = [[] for _ in video_events]\n",
    "for match, r in zip(matches, recall_events):\n",
    "    for i, m in enumerate(match):\n",
    "        avg_recalls[m].append(r[i,:])\n",
    "avg_recall_events = np.array(list(map(lambda r: np.mean(r, 0) if len(r)>0 else np.zeros((100,)), avg_recalls)))\n",
    "# avg_recall_events = np.array([a.reshape(100,) for a in avg_recall_events if a.shape==(100,)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 2D embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "embeddings = hyp.reduce(recall_events+[video_events]+[avg_recall_events], reduce='UMAP', ndims=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(datadir+'avg_recall_events', avg_recall_events)\n",
    "# np.save(datadir+'embeddings', [embeddings[:-2], embeddings[-2], embeddings[:-1]])\n",
    "# np.save(datadir+'labels', matches)\n",
    "# np.save(datadir+'recall_events', recall_events)\n",
    "# np.save(datadir+'recall_event_times', recall_event_times)\n",
    "# with open(datadir+'recall_eventseg_models', 'wb') as f:\n",
    "#     pickle.dump(recall_eventseg_models, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
