{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reproduces the parameter search (n_topics, video window size, recall window size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr as corr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import hypertools as hyp\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from scipy.signal import resample\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import correlation\n",
    "from scipy.stats import pearsonr\n",
    "from multiprocessing import Pool\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rc('figure', figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_text = pd.read_excel('../../../data/raw/Sherlock_Segments_1000_NN_2017.xlsx', )\n",
    "movie_text['Scene Segments'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First try a simple grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_models(movie, movie_wsize=50, n_components=100, recall_wsize=5, warp=True):\n",
    "\n",
    "    # create a list of overlapping text samples\n",
    "    movie_w = []\n",
    "    for idx, sentence in enumerate(movie):\n",
    "        movie_w.append(','.join(movie[idx:idx+movie_wsize]))\n",
    "\n",
    "    # vectorizer parameters\n",
    "    vectorizer = {\n",
    "        'model' : 'CountVectorizer', \n",
    "        'params' : {\n",
    "            'stop_words' : 'english'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # topic model parameters\n",
    "    semantic = {\n",
    "        'model' : 'LatentDirichletAllocation', \n",
    "        'params' : {\n",
    "            'n_components' : n_components,\n",
    "            'learning_method' : 'batch',\n",
    "            'random_state' : 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # create movie model with hypertools\n",
    "    movie_model = hyp.tools.format_data(movie_w, vectorizer=vectorizer, semantic=semantic, corpus=movie_w)[0]\n",
    "\n",
    "    # description are by scene, not TR so stretch the model to be in TRs\n",
    "    ranges =[[d['Start Time (TRs, 1.5s)'],d['End Time (TRs, 1.5s)']] for i, d in movie_text.iterrows()] \n",
    "    expanded = []\n",
    "    for i in range(1976):\n",
    "        try:\n",
    "            idx = np.where([i>=r[0] and i<=r[1] for r in ranges])[0][0]\n",
    "            expanded.append(movie_model[idx, :])\n",
    "        except:\n",
    "            expanded.append(movie_model[0, :])\n",
    "    movie_model = np.array(expanded)\n",
    "    \n",
    "    recalls = []\n",
    "    for sub in range(1, 18):\n",
    "        # load subject data\n",
    "        recall = pd.read_csv('../../../data/raw/NN'+str(sub)+' transcript.txt', header=None, sep='.', error_bad_lines=False, encoding='latin-1').values.tolist()[0][:-1]\n",
    "\n",
    "        rs = []  \n",
    "        # loop over sentences\n",
    "        for sentence in recall:\n",
    "            try:\n",
    "                s = sentence.encode('utf-8').strip()\n",
    "                rs.append(sentence)\n",
    "            except:\n",
    "                pass # skips over nans\n",
    "\n",
    "\n",
    "        # create overlapping windows of 5 sentences\n",
    "        sub_recall = []\n",
    "        for idx, sentence in enumerate(rs):\n",
    "            sub_recall.append(','.join(rs[idx:idx+recall_wsize]))\n",
    "        recalls.append(sub_recall)\n",
    "\n",
    "    # create recall models\n",
    "    recall_models = hyp.tools.format_data(recalls, vectorizer=vectorizer, semantic=semantic, corpus=movie_w)\n",
    "\n",
    "    # resample\n",
    "    recall_models_rs = list(map(lambda x: resample(x, 1976), recall_models))\n",
    "    \n",
    "    # align with dynamic time warping\n",
    "    if warp:\n",
    "        movie_models_dtw = []\n",
    "        recall_models_rs_dtw = []\n",
    "        for r in recall_models_rs:\n",
    "            distance, path = fastdtw(movie_model, r, dist=correlation)\n",
    "            m = movie_model[list(map(lambda x: x[0], path)), :]\n",
    "            r = r[list(map(lambda x: x[1], path)), :]\n",
    "            movie_models_dtw.append(m)\n",
    "            recall_models_rs_dtw.append(r)\n",
    "        recall_models_rs_dtw = list(map(lambda x: resample(x, 1976), recall_models_rs_dtw))\n",
    "        movie_models_rs_dtw = list(map(lambda x: resample(x, 1976), movie_models_dtw))\n",
    "        return movie_models_rs_dtw, recall_models_rs_dtw\n",
    "    else:\n",
    "        return movie_model, recall_models_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a list of text samples from the scene descriptions / details to train the topic model\n",
    "movie = movie_text.loc[:,'Scene Details - A Level ':'Words on Screen '].apply(lambda x: ', '.join(x.fillna('')), axis=1).values.tolist()\n",
    "movie_models, recall_models = get_models(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_topics = [5, 10, 25, 50, 100]\n",
    "movie_wsizes = [5, 10, 25, 50, 100]\n",
    "recall_wsizes = [5, 10, 25, 50, 100]\n",
    "param_grid = [(a, b, c) for a in n_topics for b in movie_wsizes for c in recall_wsizes]\n",
    "hand_rec = [27, 24, 32, 33, 32, 39, 30, 39, 28, 40, 34, 38, 47, 38, 27, 37, 39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search(movie, a, b, c):\n",
    "    movie_models, recall_models = get_models(movie, n_components=a, movie_wsize=b, recall_wsize=c)\n",
    "    movie_rec_corr = [pearsonr(m.ravel(),r.ravel())[0] for m, r in zip(movie_models, recall_models)]\n",
    "    return pearsonr(movie_rec_corr, hand_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corrs = []\n",
    "for a, b, c in param_grid:\n",
    "    corr = grid_search(movie, a, b, c)\n",
    "    corrs.append(corr)\n",
    "    print(a, b, c, corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('../../../data/processed/grid_search_results', corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_models, recall_models = get_models(movie, n_components=100, movie_wsize=50, recall_wsize=10)\n",
    "movie_rec_corr = [pearsonr(m.ravel(),r.ravel())[0] for m, r in zip(movie_models, recall_models)]\n",
    "pearsonr(movie_rec_corr, hand_rec)\n",
    "sns.jointplot(np.array(movie_rec_corr), np.array(hand_rec), kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "plt.rc('figure', figsize=(15, 3))\n",
    "# cmap = 'bone'\n",
    "f, axarr = plt.subplots(1, 5)\n",
    "for i, arr in enumerate(np.array(list(map(lambda x: x[0], corrs))).reshape(5, 5, 5)):\n",
    "    ax = sns.heatmap(arr, vmin=0, vmax=.75, xticklabels=[5, 10, 25, 50, 100], yticklabels=[5, 10, 25, 50, 100],\n",
    "                     ax=axarr[i], cbar_kws={'label': 'Correlation'})\n",
    "    ax.set_title(r'Number of topics ($K$): %s' % str(n_topics[i]))\n",
    "    ax.set_xlabel(r'Recall window width ($\\rho$)')\n",
    "    ax.set_ylabel(r'Video window width ($\\omega$)')\n",
    "#     xplt.show()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../../parameter_search.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
