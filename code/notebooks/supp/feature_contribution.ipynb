{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T16:08:46.665750Z",
     "start_time": "2019-08-25T16:08:43.103145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Helper functions and variables used across multiple notebooks can be found in `/mnt/code/sherlock_helpers/sherlock_helpers`, or on GitHub, [here](https://github.com/ContextLab/sherlock-topic-model-paper/tree/master/code/sherlock_helpers).<br />You can also view source code directly from the notebook with:<br /><pre>    from sherlock_helpers.functions import show_source<br />    show_source(foo)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hypertools as hyp\n",
    "from scipy.stats import pearsonr, sem\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sherlock_helpers.constants import (\n",
    "    DATA_DIR, \n",
    "    RAW_DIR, \n",
    "    RECALL_WSIZE,\n",
    "    SEMANTIC_PARAMS, \n",
    "    VECTORIZER_PARAMS,\n",
    "    VIDEO_WSIZE\n",
    ")\n",
    "from sherlock_helpers.functions import (\n",
    "    create_diag_mask,\n",
    "    format_text,\n",
    "    get_video_timepoints,\n",
    "    parse_windows,\n",
    "    show_source,\n",
    "    warp_recall\n",
    "    \n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define/inspect some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: #f8f8f8\"><pre style=\"line-height: 125%\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">format_text</span>(text):\n",
       "    <span style=\"color: #008000; font-weight: bold\">if</span> <span style=\"color: #008000\">isinstance</span>(text, pd<span style=\"color: #666666\">.</span>Series):\n",
       "        text <span style=\"color: #666666\">=</span> <span style=\"color: #BA2121\">&#39; &#39;</span><span style=\"color: #666666\">.</span>join(<span style=\"color: #008000\">list</span>(text<span style=\"color: #666666\">.</span>dropna()))\n",
       "        pattern <span style=\"color: #666666\">=</span> <span style=\"color: #BA2121\">&quot;[^\\w\\s]+&quot;</span>\n",
       "    <span style=\"color: #008000; font-weight: bold\">else</span>:\n",
       "        pattern <span style=\"color: #666666\">=</span> <span style=\"color: #BA2121\">&quot;[^.\\w\\s]+&quot;</span>\n",
       "\n",
       "    no_possessive <span style=\"color: #666666\">=</span> text<span style=\"color: #666666\">.</span>lower()<span style=\"color: #666666\">.</span>replace(<span style=\"color: #BA2121\">&quot;&#39;s&quot;</span>, <span style=\"color: #BA2121\">&#39;&#39;</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">return</span> re<span style=\"color: #666666\">.</span>sub(pattern, <span style=\"color: #BA2121\">&#39;&#39;</span>, no_possessive)\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_source(format_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: #f8f8f8\"><pre style=\"line-height: 125%\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">parse_windows</span>(textlist, wsize):\n",
       "    windows <span style=\"color: #666666\">=</span> []\n",
       "    window_bounds <span style=\"color: #666666\">=</span> []\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> ix <span style=\"color: #AA22FF; font-weight: bold\">in</span> <span style=\"color: #008000\">range</span>(<span style=\"color: #666666\">1</span>, wsize):\n",
       "        start, end <span style=\"color: #666666\">=</span> <span style=\"color: #666666\">0</span>, ix\n",
       "        window_bounds<span style=\"color: #666666\">.</span>append((start, end))\n",
       "        windows<span style=\"color: #666666\">.</span>append(<span style=\"color: #BA2121\">&#39; &#39;</span><span style=\"color: #666666\">.</span>join(textlist[start:end]))\n",
       "\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> ix <span style=\"color: #AA22FF; font-weight: bold\">in</span> <span style=\"color: #008000\">range</span>(<span style=\"color: #008000\">len</span>(textlist)):\n",
       "        start <span style=\"color: #666666\">=</span> ix\n",
       "        end <span style=\"color: #666666\">=</span> ix <span style=\"color: #666666\">+</span> wsize <span style=\"color: #008000; font-weight: bold\">if</span> ix <span style=\"color: #666666\">+</span> wsize <span style=\"color: #666666\">&lt;=</span> <span style=\"color: #008000\">len</span>(textlist) <span style=\"color: #008000; font-weight: bold\">else</span> <span style=\"color: #008000\">len</span>(textlist)\n",
       "        window_bounds<span style=\"color: #666666\">.</span>append((start, end))\n",
       "        windows<span style=\"color: #666666\">.</span>append(<span style=\"color: #BA2121\">&#39; &#39;</span><span style=\"color: #666666\">.</span>join(textlist[start:end]))\n",
       "\n",
       "    <span style=\"color: #008000; font-weight: bold\">return</span> windows, window_bounds\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_source(parse_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: #f8f8f8\"><pre style=\"line-height: 125%\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">get_video_timepoints</span>(window_spans, annotations):\n",
       "    timepoints <span style=\"color: #666666\">=</span> []\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> first, last <span style=\"color: #AA22FF; font-weight: bold\">in</span> window_spans:\n",
       "        window_onset <span style=\"color: #666666\">=</span> annotations<span style=\"color: #666666\">.</span>loc[first, <span style=\"color: #BA2121\">&#39;Start Time (s) &#39;</span>]\n",
       "        window_offset <span style=\"color: #666666\">=</span> annotations<span style=\"color: #666666\">.</span>loc[last <span style=\"color: #666666\">-</span> <span style=\"color: #666666\">1</span>, <span style=\"color: #BA2121\">&#39;End Time (s) &#39;</span>]\n",
       "        timepoints<span style=\"color: #666666\">.</span>append((window_onset <span style=\"color: #666666\">+</span> window_offset) <span style=\"color: #666666\">/</span> <span style=\"color: #666666\">2</span>)\n",
       "\n",
       "    <span style=\"color: #008000; font-weight: bold\">return</span> np<span style=\"color: #666666\">.</span>array(timepoints)\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_source(get_video_timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: #f8f8f8\"><pre style=\"line-height: 125%\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">create_diag_mask</span>(arr, diag_start<span style=\"color: #666666\">=0</span>, diag_limit<span style=\"color: #666666\">=</span><span style=\"color: #008000\">None</span>):\n",
       "    diag_mask <span style=\"color: #666666\">=</span> np<span style=\"color: #666666\">.</span>zeros_like(arr, dtype<span style=\"color: #666666\">=</span><span style=\"color: #008000\">bool</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">if</span> diag_limit <span style=\"color: #AA22FF; font-weight: bold\">is</span> <span style=\"color: #008000\">None</span>:\n",
       "        diag_limit <span style=\"color: #666666\">=</span> find_diag_limit(arr)\n",
       "\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> k <span style=\"color: #AA22FF; font-weight: bold\">in</span> <span style=\"color: #008000\">range</span>(diag_start, diag_limit):\n",
       "        ix <span style=\"color: #666666\">=</span> kth_diag_indices(diag_mask, k)\n",
       "        diag_mask[ix] <span style=\"color: #666666\">=</span> <span style=\"color: #008000\">True</span>\n",
       "\n",
       "    <span style=\"color: #008000; font-weight: bold\">return</span> diag_mask\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_source(create_diag_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wrap full topic modeling pipeline\n",
    "def transform_video(annotations):\n",
    "    dropcols = ['Start Time (s) ', 'End Time (s) ', \n",
    "                'Start Time (TRs, 1.5s)', 'End Time (TRs, 1.5s)']\n",
    "    features = annotations.drop(columns=dropcols)\n",
    "    scenes_list = features.apply(format_text, axis=1).tolist()\n",
    "    video_windows, window_bounds = parse_windows(scenes_list, VIDEO_WSIZE)\n",
    "    video_model = hyp.tools.format_data(video_windows, \n",
    "                                        vectorizer=VECTORIZER_PARAMS, \n",
    "                                        semantic=SEMANTIC_PARAMS, \n",
    "                                        corpus=video_windows)[0]\n",
    "    \n",
    "    video_model_TRs = np.empty((1976, 100))\n",
    "    xvals = get_video_timepoints(window_bounds, annotations)\n",
    "    xvals_TR = np.array(xvals) * 1976 / 2963\n",
    "    TR_times = np.arange(1, 1977)\n",
    "    interp_func = interp1d(xvals_TR, \n",
    "                           video_model, \n",
    "                           axis=0, \n",
    "                           fill_value='extrapolate')\n",
    "    video_model_TRs = interp_func(TR_times)\n",
    "    return video_model_TRs, video_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_recalls(recall_windows, video_windows, video_traj):\n",
    "    recall_models = hyp.tools.format_data(recall_windows, \n",
    "                                          vectorizer=VECTORIZER_PARAMS, \n",
    "                                          semantic=SEMANTIC_PARAMS, \n",
    "                                          corpus=video_windows)\n",
    "    # warp recall trajectores to video trajectory length\n",
    "    return [warp_recall(r, video_traj, return_paths=False) for r in recall_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlate_structures(video, other):\n",
    "    assert video.shape == other.shape\n",
    "    vcorr = np.corrcoef(video)\n",
    "    ocorr = np.corrcoef(other)\n",
    "    # diag_limit precomputed from intact video\n",
    "    diag_mask = create_diag_mask(vcorr, diag_start=1, diag_limit=238)\n",
    "    v = vcorr[diag_mask]\n",
    "    o = ocorr[diag_mask]\n",
    "    return pearsonr(v, o)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Narrative details', 'Indoor vs outdoor', 'Characters on screen', \n",
    "            'Character in focus', 'Character speaking', 'Location', \n",
    "            'Camera angle', 'Music presence', 'Text on screen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T16:08:46.908326Z",
     "start_time": "2019-08-25T16:08:46.671869Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_text = pd.read_excel(RAW_DIR.joinpath('Sherlock_Segments_1000_NN_2017.xlsx'))\n",
    "video_text['Scene Segments'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# drop 1s shot & 6s of black screen after end of 1st scan\n",
    "video_text.drop(index=[480, 481], inplace=True)\n",
    "video_text.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# timestamps for 2nd scan restart from 0; add duration of 1st scan to values\n",
    "video_text.loc[480:, 'Start Time (s) ':'End Time (s) '] += video_text.loc[479, 'End Time (s) ']\n",
    "\n",
    "keep_cols = np.append(video_text.columns[1:5], video_text.columns[6:15])\n",
    "video_text = video_text.loc[:, keep_cols]\n",
    "video_text.columns = list(video_text.columns[:4]) + features\n",
    "\n",
    "# trajectories created from all features\n",
    "full_video, full_recalls = np.load(DATA_DIR.joinpath('models_t100_v50_r10.npy'), \n",
    "                                   allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_w = []\n",
    "for sub in range(1, 18):\n",
    "    transcript_path = RAW_DIR.joinpath(f'NN{sub} transcript.txt')\n",
    "    with transcript_path.open(encoding='cp1252') as f:\n",
    "        recall = f.read().replace(b'\\x92'.decode('cp1252'), \"'\").strip()\n",
    "    \n",
    "    recall_fmt = format_text(recall).split('.')\n",
    "    if not recall_fmt[-1]:\n",
    "        recall_fmt = recall_fmt[:-1]\n",
    "    \n",
    "    sub_recall_w = parse_windows(recall_fmt, RECALL_WSIZE)[0]\n",
    "    recall_w.append(sub_recall_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratively hold out one feature and transform remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T16:12:20.469876Z",
     "start_time": "2019-08-25T16:08:47.110997Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca33381bf40344f1bd685ee73096040b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narrative details:\n",
      "\tsimilarity to full video: 0.7840464784236999\n",
      "\tvideo-recall structure similarity: 0.49789433751038686, SEM: 0.03575362265021856\n",
      "\n",
      "Indoor vs outdoor:\n",
      "\tsimilarity to full video: 0.8576974275883418\n",
      "\tvideo-recall structure similarity: 0.6569000158177016, SEM: 0.027134409621705116\n",
      "\n",
      "Characters on screen:\n",
      "\tsimilarity to full video: 0.7976882761325998\n",
      "\tvideo-recall structure similarity: 0.6818517096348622, SEM: 0.027818639564926455\n",
      "\n",
      "Character in focus:\n",
      "\tsimilarity to full video: 0.873694587735584\n",
      "\tvideo-recall structure similarity: 0.5982538568209149, SEM: 0.03024753485130499\n",
      "\n",
      "Character speaking:\n",
      "\tsimilarity to full video: 0.8651720030104021\n",
      "\tvideo-recall structure similarity: 0.6303607927331502, SEM: 0.03204785143227152\n",
      "\n",
      "Location:\n",
      "\tsimilarity to full video: 0.7871552037453584\n",
      "\tvideo-recall structure similarity: 0.68326123617632, SEM: 0.025844925341076984\n",
      "\n",
      "Camera angle:\n",
      "\tsimilarity to full video: 0.8431489481128159\n",
      "\tvideo-recall structure similarity: 0.6603313082637992, SEM: 0.028157417303993324\n",
      "\n",
      "Music presence:\n",
      "\tsimilarity to full video: 0.8612995667404652\n",
      "\tvideo-recall structure similarity: 0.6342366880258695, SEM: 0.028670715955777595\n",
      "\n",
      "Text on screen:\n",
      "\tsimilarity to full video: 0.860868030083184\n",
      "\tvideo-recall structure similarity: 0.653464523885414, SEM: 0.028586727849905673\n",
      "\n",
      "All features\n",
      "\tvideo-recall structure similarity: 0.6520455401584276, SEM: 0.026843846623524615\n"
     ]
    }
   ],
   "source": [
    "analyses = ['full vid corr', 'vid rec corr', 'vid rec sem']\n",
    "dropfeat_corrs = pd.DataFrame(index=features, columns=analyses)\n",
    "\n",
    "for feature in tqdm(features, leave=False):\n",
    "    print(f'{feature}:')\n",
    "    # transform remaining annotations\n",
    "    other_features = video_text.drop(feature, axis=1)\n",
    "    dropfeat_vid, dropfeat_vid_ws = transform_video(other_features)\n",
    "    \n",
    "    # compute similarity with full-feature video trajectory structure\n",
    "    full_video_corr = correlate_structures(full_video, dropfeat_vid)\n",
    "    \n",
    "    # transform recalls using feature-removed corpus\n",
    "    dropfeat_recs = transform_recalls(recall_w, dropfeat_vid_ws, dropfeat_vid)\n",
    "    \n",
    "    # compare structures to partial video model\n",
    "    rec_corrs = np.array([correlate_structures(dropfeat_vid, r) \n",
    "                          for r in dropfeat_recs])\n",
    "    feat_corr, feat_sem = rec_corrs.mean(), sem(rec_corrs)\n",
    "\n",
    "    dropfeat_corrs.loc[feature] = [full_video_corr, feat_corr, feat_sem]\n",
    "    print(f'\\tsimilarity to full video: {full_video_corr}')\n",
    "    print(f'\\tvideo-recall structure similarity: {feat_corr}, SEM: {feat_sem}\\n')\n",
    "    \n",
    "# add data for full model\n",
    "rec_corr_full = np.array([\n",
    "    correlate_structures(full_video, warp_recall(r, full_video, return_paths=False)) \n",
    "    for r in full_recalls\n",
    "])\n",
    "dropfeat_corrs.loc['All features'] = [1, rec_corr_full.mean(), sem(rec_corr_full)]\n",
    "print('All features')\n",
    "print(f'\\tvideo-recall structure similarity: {rec_corr_full.mean()}, SEM: {sem(rec_corr_full)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropfeat_corrs.to_pickle(DATA_DIR.joinpath('feature_contribution.p'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
