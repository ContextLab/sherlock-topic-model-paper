{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T18:29:51.029932Z",
     "start_time": "2019-08-25T18:29:49.503297Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import random\n",
    "from os.path import join as opj\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from wordcloud import WordCloud, get_single_color_func\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import seaborn as sns\n",
    "\n",
    "cmap = plt.cm.Spectral\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T18:29:51.323602Z",
     "start_time": "2019-08-25T18:29:51.031243Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topn(d, n):\n",
    "    c = collections.Counter(d)\n",
    "    return {k:v for k, v in c.most_common(n)}\n",
    "\n",
    "\n",
    "def get_normalized_model(m, tm):\n",
    "    m = np.dot(m, tm.components_)\n",
    "    m-=m.mean(0)\n",
    "    m-=np.min(m)\n",
    "    m/=np.max(m)\n",
    "    return m\n",
    "\n",
    "\n",
    "class SimpleGroupedColorFunc(object):\n",
    "    \"\"\"Create a color function object which assigns EXACT colors\n",
    "       to certain words based on the color to words mapping\n",
    "       Parameters\n",
    "       ----------\n",
    "       color_to_words : dict(str -> list(str))\n",
    "         A dictionary that maps a color to the list of words.\n",
    "       default_color : str\n",
    "         Color that will be assigned to a word that's not a member\n",
    "         of any value from color_to_words.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, color_to_words, default_color):\n",
    "        self.word_to_color = {word: color\n",
    "                              for (color, words) in color_to_words.items()\n",
    "                              for word in words}\n",
    "\n",
    "        self.default_color = default_color\n",
    "\n",
    "    def __call__(self, word, **kwargs):\n",
    "        return self.word_to_color.get(word, self.default_color)\n",
    "    \n",
    "    \n",
    "def plot_wordle(ax, textdict, maskpath=None):\n",
    "    circle = np.array(Image.open(maskpath))\n",
    "    wc = WordCloud(max_font_size=50, collocations=False, max_words=200, background_color=\"white\", mask=circle, width=2000, height=1000, colormap=plt.cm.Reds)\n",
    "    wc.generate_from_frequencies(textdict)\n",
    "    ax.imshow(wc.recolor(color_func=grouped_color_func, random_state=3),\n",
    "           interpolation=\"bilinear\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    \n",
    "def plot_image(x, y, image, ax=None, zoom=1):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    try:\n",
    "        image = plt.imread(image)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    im = OffsetImage(image, zoom=zoom)\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    im.image.axes=ax\n",
    "    artists = []\n",
    "    ab = AnnotationBbox(im, (x, y), xycoords='data', frameon=False)\n",
    "    artists.append(ax.add_artist(ab))\n",
    "    return artists\n",
    "\n",
    "\n",
    "def add_arrows(axes, x, y, **kwargs):\n",
    "    # spacing of arrows\n",
    "    aspace = .05 # good value for scale of 1\n",
    "    aspace *= scale\n",
    "\n",
    "    # r is the distance spanned between pairs of points\n",
    "    r = [0]\n",
    "    for i in range(1,len(x)):\n",
    "        dx = x[i]-x[i-1]\n",
    "        dy = y[i]-y[i-1]\n",
    "        r.append(np.sqrt(dx*dx+dy*dy))\n",
    "    r = np.array(r)\n",
    "\n",
    "    # rtot is a cumulative sum of r, it's used to save time\n",
    "    rtot = []\n",
    "    for i in range(len(r)):\n",
    "        rtot.append(r[0:i].sum())\n",
    "    rtot.append(r.sum())\n",
    "\n",
    "    arrowData = [] # will hold tuples of x,y,theta for each arrow\n",
    "    arrowPos = 0 # current point on walk along data\n",
    "    rcount = 1 \n",
    "    while arrowPos < r.sum():\n",
    "        x1,x2 = x[rcount-1],x[rcount]\n",
    "        y1,y2 = y[rcount-1],y[rcount]\n",
    "        da = arrowPos-rtot[rcount] \n",
    "        theta = np.arctan2((x2-x1),(y2-y1))\n",
    "        ax = np.sin(theta)*da+x1\n",
    "        ay = np.cos(theta)*da+y1\n",
    "        arrowData.append((ax,ay,theta))\n",
    "        arrowPos+=aspace\n",
    "        while arrowPos > rtot[rcount+1]: \n",
    "            rcount+=1\n",
    "            if arrowPos > rtot[-1]:\n",
    "                break\n",
    "\n",
    "    # could be done in above block if you want\n",
    "    for ax,ay,theta in arrowData:\n",
    "        # use aspace as a guide for size and length of things\n",
    "        # scaling factors were chosen by experimenting a bit\n",
    "        axes.arrow(ax,ay,\n",
    "                   np.sin(theta)*aspace/10,np.cos(theta)*aspace/10, \n",
    "                   head_width=aspace/3, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T18:29:51.389920Z",
     "start_time": "2019-08-25T18:29:51.325171Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _z2r(z):\n",
    "    \"\"\"\n",
    "    Function that calculates the inverse Fisher z-transformation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : int or ndarray\n",
    "        Fishers z transformed correlation value\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    result : int or ndarray\n",
    "        Correlation value\n",
    "\n",
    "    \"\"\"\n",
    "    z = np.array(z)\n",
    "    with np.errstate(invalid='ignore', divide='ignore'):\n",
    "        return (np.exp(2 * z) - 1) / (np.exp(2 * z) + 1)\n",
    "    \n",
    "\n",
    "def _r2z(r):\n",
    "    \"\"\"\n",
    "    Function that calculates the Fisher z-transformation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r : int or ndarray\n",
    "        Correlation value\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    result : int or ndarray\n",
    "        Fishers z transformed correlation value\n",
    "\n",
    "    \"\"\"\n",
    "    r = np.array(r)\n",
    "    with np.errstate(invalid='ignore', divide='ignore'):\n",
    "        return 0.5 * (np.log(1 + r) - np.log(1 - r))\n",
    "    \n",
    "    \n",
    "def corr_mean(rs, axis=0):\n",
    "    \"\"\"\n",
    "    Function that calculates the mean of correlation coefficients,\n",
    "    performing Fisher z-transformation and inverse z-transormation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rs: : list or ndarray\n",
    "        Correlation values\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    result : float\n",
    "        mean of correlation values\n",
    "\n",
    "    \"\"\"\n",
    "    return _z2r(np.nanmean([_r2z(r) for r in rs], axis=axis))\n",
    "\n",
    "\n",
    "def bootstrap_ci_corrs(M, ci=95, n_boots=1000, color='#1f77b4', alpha=0.2, label=None):\n",
    "    evs = np.arange(M.shape[0])\n",
    "    y = corr_mean(M, axis=1)\n",
    "    ci_low = (100 - ci) / 2\n",
    "    ci_high = 100 - ci_low\n",
    "    L, U = np.empty(evs.shape), np.empty(evs.shape)\n",
    "    # constructs a single resample\n",
    "    boot_mean = lambda x: np.nanmean(np.random.choice(x[~np.isnan(x)], size=len(x), replace=True))\n",
    "    \n",
    "    for ev in evs:\n",
    "        zev_dists = _r2z(M[ev])\n",
    "        boot_iter = (boot_mean(zev_dists) for n in range(n_boots))\n",
    "        zboots = np.fromiter(boot_iter, dtype=float)\n",
    "        # use percentile bootstrap (seaborn default method)\n",
    "        L[ev], U[ev] = _z2r(np.percentile(zboots, ci_low)), _z2r(np.percentile(zboots, ci_high))\n",
    "    \n",
    "    # error ribbons\n",
    "    h1 = plt.fill_between(evs, L, U, color=color, alpha=alpha)\n",
    "    # opaque line\n",
    "    h2 = plt.plot(evs, y, color=color, label=label)\n",
    "    return h1, h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T18:29:51.394785Z",
     "start_time": "2019-08-25T18:29:51.391653Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = '../../../data/processed/'\n",
    "figdir = '../../../paper/figs/'\n",
    "tmp_dir = opj(figdir, 'tmp')\n",
    "# os.mkdir(tmp_dir)\n",
    "\n",
    "default_color = 'grey'\n",
    "n = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T18:29:51.546052Z",
     "start_time": "2019-08-25T18:29:51.396146Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_events = np.load(opj(datadir, 'video_events.npy'))\n",
    "recall_events = np.load(opj(datadir, 'recall_events.npy'), allow_pickle=True)\n",
    "avg_recall_events = np.load(opj(datadir, 'avg_recall_events.npy'), allow_pickle=True)\n",
    "matches = np.load(opj(datadir, 'labels.npy'), allow_pickle=True)\n",
    "text_corpus = np.load(opj(datadir, 'video_text.npy'), allow_pickle=True)\n",
    "embeddings = np.load(opj(datadir, 'embeddings.npy'), allow_pickle=True)\n",
    "video_embedding = embeddings[0]\n",
    "recall_embeddings = embeddings[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists = [[] for _ in video_events]\n",
    "\n",
    "for sub, rec in enumerate(recall_events):\n",
    "    ms = matches[sub]\n",
    "    prec = np.diag(1 - cdist(video_events[ms], rec, 'correlation'))\n",
    "    for v_ix, m in enumerate(ms):\n",
    "        dists[m].append(prec[v_ix])\n",
    "\n",
    "most_matched = np.max([np.shape(i)[0] for i in dists])\n",
    "for i, d in enumerate(dists):\n",
    "    while len(d) < max_len:\n",
    "        d.append(np.nan)\n",
    "dists = np.array(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T18:29:53.008067Z",
     "start_time": "2019-08-25T18:29:51.598604Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "bootstrap_ci_corrs(dists)\n",
    "plt.xlim(0,29)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Event number')\n",
    "plt.ylabel('Average correlation')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(opj(tmp_dir, 'precision.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit topic model to video annotation sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "fit_cv = cv.fit_transform(text_corpus)\n",
    "tm = LatentDirichletAllocation(n_components=100, learning_method='batch', random_state=0).fit(fit_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(opj(datadir, 'count_vectorizer_model'), cv)\n",
    "np.save(opj(datadir, 'topic_model'), tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T18:29:53.013863Z",
     "start_time": "2019-08-25T18:29:53.009418Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_video_events = get_normalized_model(video_events, tm)\n",
    "norm_avg_recall_events = get_normalized_model(avg_recall_events, tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordle figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T18:30:03.759581Z",
     "start_time": "2019-08-25T18:29:53.015000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for seg in range(video_events.shape[0]):\n",
    "    weights = norm_video_events[seg, :]\n",
    "    textdict_video = topn({word: weight for word, weight in zip(cv.get_feature_names(), weights)}, n)\n",
    "    weights = norm_avg_recall_events[seg,:]\n",
    "    textdict_recall = topn({word: weight for word, weight in zip(cv.get_feature_names(), weights)}, n)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    color_to_words = {'black': list(set(textdict_video))}\n",
    "    grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)\n",
    "    plot_wordle(ax1, textdict_video, maskpath=opj(datadir, \"half-moon-left.jpg\"))\n",
    "    color_to_words = {'black': list(set(textdict_recall))}\n",
    "    grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)\n",
    "    plot_wordle(ax2, textdict_recall, maskpath=opj(datadir, \"half-moon.jpg\"))\n",
    "    plt.subplots_adjust(wspace=-.5, hspace=-.5)\n",
    "    fig.patch.set_visible(False)\n",
    "#     plt.savefig(opj(tmp_dir, f'wordle_event{seg}.png'), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted average of the event vectors by memorability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T18:30:03.775327Z",
     "start_time": "2019-08-25T18:30:03.761571Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdist = corr_mean(dists, axis=1)\n",
    "rvec = np.zeros_like(video_events[0])\n",
    "fvec = np.zeros_like(video_events[0])\n",
    "rsum = 0\n",
    "fsum = 0\n",
    "for v, w in zip(video_events, mdist):\n",
    "    rvec += v * w\n",
    "    rsum += w\n",
    "    fvec += v * (1 - w)\n",
    "    fsum += (1 - w)\n",
    "r = rvec / rsum\n",
    "r = r - video_events.mean(0)\n",
    "f = fvec / fsum\n",
    "f = f - video_events.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most memorable words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T18:30:04.292805Z",
     "start_time": "2019-08-25T18:30:03.776890Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rweights = np.dot(r, tm.components_)\n",
    "rdict = topn({word:weight for word, weight in zip(cv.get_feature_names(), rweights)}, 200)\n",
    "fig, ax1 = plt.subplots(1, 1)\n",
    "color_to_words = {'black': list(set(rdict))}\n",
    "grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)\n",
    "plot_wordle(ax1, rdict, maskpath=opj(datadir, \"oval2.jpg\"))\n",
    "# plt.savefig(opj(tmp_dir, 'most_memorable.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least memorable words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T18:30:04.834113Z",
     "start_time": "2019-08-25T18:30:04.294279Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fweights = np.dot(f, tm.components_)\n",
    "fdict = topn({word:weight for word, weight in zip(cv.get_feature_names(), fweights)}, 200)\n",
    "fig, ax1 = plt.subplots(1, 1)\n",
    "color_to_words = {'black': list(set(fdict))}\n",
    "grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)\n",
    "plot_wordle(ax1, fdict, maskpath=opj(datadir, \"oval2.jpg\"))\n",
    "# plt.savefig(opj(tmp_dir, 'least_memorable.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory distribution figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T18:30:06.761368Z",
     "start_time": "2019-08-25T18:30:04.835458Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = cmap(np.linspace(0, 1, 10))\n",
    "sub_color = cmap(np.linspace(0, 1, 17))\n",
    "subj_points = np.vstack(recall_embeddings)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "scale = 30\n",
    "for i, (sub, sub_match) in enumerate(zip(recall_embeddings, matches)):\n",
    "    for j, (p, m) in enumerate(zip(sub, sub_match)):\n",
    "        ax.plot(p[0], p[1], 'o', c=cmap(m/video_embedding.shape[0]), alpha=.75, zorder=2, markersize=7)\n",
    "        ax.plot(p[0], p[1], 'o', c='k', alpha=.5, zorder=1, markersize=8)\n",
    "hinges = video_embedding\n",
    "for i in range(len(hinges)-1):\n",
    "    ax.plot([hinges[i, 0], hinges[i+1, 0]], [hinges[i, 1], hinges[i+1, 1]], c='k', linewidth=2, alpha=1)\n",
    "for i in range(len(hinges)):\n",
    "    ax.plot(hinges[i,0], hinges[i,1], 'o', c=cmap(i/hinges.shape[0]), zorder=4, markersize=mdist[i]*scale/3+5, alpha=.9)\n",
    "    ax.plot(hinges[i,0], hinges[i,1], 'ko', zorder=3, markersize=mdist[i]*scale/3+7, alpha=.9)\n",
    "add_arrows(ax, hinges[:, 0], hinges[:, 1], zorder=3, alpha=1, color='k', fill=True)\n",
    "ax.axis('off')\n",
    "# plt.savefig(opj(tmp_dir, 'trajectory_distribution.pdf'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
