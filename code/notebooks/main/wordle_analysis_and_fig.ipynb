{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import cdist\n",
    "import collections\n",
    "from PIL import Image\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from wordcloud import WordCloud, get_single_color_func\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "\n",
    "cmap = plt.cm.Spectral\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2dict(text):\n",
    "    cv = CountVectorizer(stop_words='english')\n",
    "    cv_text = cv.fit_transform([text])\n",
    "    return {k:v for k,v in zip(cv.get_feature_names(), cv_text.toarray().ravel())}\n",
    "\n",
    "def topn(d, n):\n",
    "    c = collections.Counter(d)\n",
    "    return {k:v for k, v in c.most_common(n)}\n",
    "\n",
    "def get_normalized_model(m, tm):\n",
    "    m = np.dot(m, tm.components_)\n",
    "    m-=m.mean(0)\n",
    "    m-=np.min(m)\n",
    "    m/=np.max(m)\n",
    "    return m\n",
    "\n",
    "class SimpleGroupedColorFunc(object):\n",
    "    \"\"\"Create a color function object which assigns EXACT colors\n",
    "       to certain words based on the color to words mapping\n",
    "       Parameters\n",
    "       ----------\n",
    "       color_to_words : dict(str -> list(str))\n",
    "         A dictionary that maps a color to the list of words.\n",
    "       default_color : str\n",
    "         Color that will be assigned to a word that's not a member\n",
    "         of any value from color_to_words.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, color_to_words, default_color):\n",
    "        self.word_to_color = {word: color\n",
    "                              for (color, words) in color_to_words.items()\n",
    "                              for word in words}\n",
    "\n",
    "        self.default_color = default_color\n",
    "\n",
    "    def __call__(self, word, **kwargs):\n",
    "        return self.word_to_color.get(word, self.default_color)\n",
    "    \n",
    "def plot_wordle(ax, textdict, maskpath=None):\n",
    "    circle = np.array(Image.open(maskpath))\n",
    "    wc = WordCloud(max_font_size=50, collocations=False, max_words=200, background_color=\"white\", mask=circle, width=2000, height=1000, colormap=plt.cm.Reds)\n",
    "    wc.generate_from_frequencies(textdict)\n",
    "    ax.imshow(wc.recolor(color_func=grouped_color_func, random_state=3),\n",
    "           interpolation=\"bilinear\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "def plot_image(x, y, image, ax=None, zoom=1):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    try:\n",
    "        image = plt.imread(image)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    im = OffsetImage(image, zoom=zoom)\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    im.image.axes=ax\n",
    "    artists = []\n",
    "    ab = AnnotationBbox(im, (x, y), xycoords='data', frameon=False)\n",
    "    artists.append(ax.add_artist(ab))\n",
    "#     ax.update_datalim(np.column_stack([x, y]))\n",
    "#     ax.autoscale()\n",
    "    return artists\n",
    "\n",
    "def add_arrows(axes, x, y, **kwargs):\n",
    "\n",
    "    # spacing of arrows\n",
    "    aspace = .05 # good value for scale of 1\n",
    "    aspace *= scale\n",
    "\n",
    "    # r is the distance spanned between pairs of points\n",
    "    r = [0]\n",
    "    for i in range(1,len(x)):\n",
    "        dx = x[i]-x[i-1]\n",
    "        dy = y[i]-y[i-1]\n",
    "        r.append(np.sqrt(dx*dx+dy*dy))\n",
    "    r = np.array(r)\n",
    "\n",
    "    # rtot is a cumulative sum of r, it's used to save time\n",
    "    rtot = []\n",
    "    for i in range(len(r)):\n",
    "        rtot.append(r[0:i].sum())\n",
    "    rtot.append(r.sum())\n",
    "\n",
    "    arrowData = [] # will hold tuples of x,y,theta for each arrow\n",
    "    arrowPos = 0 # current point on walk along data\n",
    "    rcount = 1 \n",
    "    while arrowPos < r.sum():\n",
    "        x1,x2 = x[rcount-1],x[rcount]\n",
    "        y1,y2 = y[rcount-1],y[rcount]\n",
    "        da = arrowPos-rtot[rcount] \n",
    "        theta = np.arctan2((x2-x1),(y2-y1))\n",
    "        ax = np.sin(theta)*da+x1\n",
    "        ay = np.cos(theta)*da+y1\n",
    "        arrowData.append((ax,ay,theta))\n",
    "        arrowPos+=aspace\n",
    "        while arrowPos > rtot[rcount+1]: \n",
    "            rcount+=1\n",
    "            if arrowPos > rtot[-1]:\n",
    "                break\n",
    "\n",
    "    # could be done in above block if you want\n",
    "    for ax,ay,theta in arrowData:\n",
    "        # use aspace as a guide for size and length of things\n",
    "        # scaling factors were chosen by experimenting a bit\n",
    "        axes.arrow(ax,ay,\n",
    "                   np.sin(theta)*aspace/10,np.cos(theta)*aspace/10, \n",
    "                   head_width=aspace/3, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = '../../../data/processed/'\n",
    "default_color = 'grey'\n",
    "n=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_events = np.load(fdir+'video_events.npy')\n",
    "recall_events = np.load(fdir+'recall_events.npy')\n",
    "avg_recall_events = np.load(fdir+'avg_recall_events.npy')\n",
    "video_embeddings = np.load(fdir+'embeddings.npy')[-2]\n",
    "recall_embeddings = np.load(fdir+'embeddings.npy')[:-2]\n",
    "matches = np.load(fdir+'labels.npy')\n",
    "tm = np.load(fdir+'topic_model')\n",
    "cv = np.load(fdir+'count_vectorizer_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = []\n",
    "for v in video_events:\n",
    "    dist = []\n",
    "    for sub in recall_events:\n",
    "        dist.append(np.max(1 - cdist(np.atleast_2d(v), sub, 'correlation')))\n",
    "    dists.append(dist)\n",
    "dists = np.array(dists)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "df = pd.DataFrame(dists)\n",
    "df = df.melt(var_name='subject', value_name='Average correlation')\n",
    "df['Event number']=list(range(34))*17\n",
    "sns.lineplot(x='Event number', y='Average correlation', data=df)\n",
    "plt.tight_layout()\n",
    "plt.xlim(0, 33)\n",
    "# plt.savefig('../figures/sme.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_video_events = get_normalized_model(video_events, tm)\n",
    "norm_avg_recall_events = get_normalized_model(avg_recall_events, tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordle figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seg in range(34):\n",
    "    weights = norm_video_events[seg,:]\n",
    "    textdict_video = topn({word:weight for word, weight in zip(cv.get_feature_names(), weights)}, n)\n",
    "    weights = norm_avg_recall_events[seg,:]\n",
    "    textdict_recall = topn({word:weight for word, weight in zip(cv.get_feature_names(), weights)}, n)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    color_to_words = {'black': list(set(textdict_video))}\n",
    "    grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)\n",
    "    plot_wordle(ax1, textdict_video, maskpath=fdir+\"half-moon-left.jpg\")\n",
    "    color_to_words = {'black': list(set(textdict_recall))}\n",
    "    grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)\n",
    "    plot_wordle(ax2, textdict_recall, maskpath=fdir+\"half-moon.jpg\")\n",
    "    plt.subplots_adjust(wspace=-.5, hspace=-.5)\n",
    "    fig.patch.set_visible(False)\n",
    "#     plt.savefig('../figures/wordle%d.png' % seg, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted average of the event vectors by memorability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdist = dists.mean(1)\n",
    "rvec = np.zeros_like(video_events[0])\n",
    "fvec = np.zeros_like(video_events[0])\n",
    "rsum=0\n",
    "fsum=0\n",
    "for v, w in zip(video_events, mdist):\n",
    "    rvec+=v*w\n",
    "    rsum+=w\n",
    "    fvec+=v*(1-w)\n",
    "    fsum+=(1-w)\n",
    "# ax1 = plt.bar(range(100), rvec/rsum)\n",
    "# plt.ylim(0, .1)\n",
    "# plt.show()\n",
    "r = rvec/rsum\n",
    "r = r - video_events.mean(0)\n",
    "f = fvec/fsum\n",
    "f = f - video_events.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most memorable words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rweights = np.dot(r, tm.components_)\n",
    "rdict = topn({word:weight for word, weight in zip(cv.get_feature_names(), rweights)}, 200)\n",
    "fig, ax1 = plt.subplots(1, 1)\n",
    "color_to_words = {'black': list(set(rdict))}\n",
    "grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)\n",
    "plot_wordle(ax1, rdict, maskpath=fdir+\"oval2.jpg\")\n",
    "# fig.patch.set_visible(False)\n",
    "# plt.savefig('../figures/wordle_r.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least memorable words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fweights = np.dot(f, tm.components_)\n",
    "fdict = topn({word:weight for word, weight in zip(cv.get_feature_names(), fweights)}, 200)\n",
    "fig, ax1 = plt.subplots(1, 1)\n",
    "color_to_words = {'black': list(set(fdict))}\n",
    "grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)\n",
    "plot_wordle(ax1, fdict, maskpath=fdir+\"oval2.jpg\")\n",
    "# plt.savefig('../figures/wordle_f.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory distribution figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cmap(np.linspace(0, 1, 10))\n",
    "sub_color = cmap(np.linspace(0, 1, 17))\n",
    "subj_points = np.vstack(recall_embeddings)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "scale=10\n",
    "for i, (sub, sub_match) in enumerate(zip(recall_embeddings, matches)):\n",
    "    for j, (p, m) in enumerate(zip(sub, sub_match)):\n",
    "        ax.plot(p[0], p[1], 'o', c=cmap(m/34), alpha=.75, zorder=2, markersize=7)\n",
    "        ax.plot(p[0], p[1], 'o', c='k', alpha=.5, zorder=1, markersize=8)\n",
    "hinges = video_embeddings\n",
    "for i in range(len(hinges)-1):\n",
    "    ax.plot([hinges[i, 0], hinges[i+1, 0]], [hinges[i, 1], hinges[i+1, 1]], c='k', linewidth=2, alpha=1)\n",
    "for i in range(len(hinges)):\n",
    "    ax.plot(hinges[i,0], hinges[i,1], 'o', c=cmap(i/34), zorder=4, markersize=mdist[i]*scale+5, alpha=.9)\n",
    "    ax.plot(hinges[i,0], hinges[i,1], 'ko', zorder=3, markersize=mdist[i]*scale+7, alpha=.9)\n",
    "add_arrows(ax, hinges[:, 0], hinges[:, 1], zorder=3, alpha=1, color='k', fill=True)\n",
    "ax.axis('off')\n",
    "# plt.savefig('../figures/gist2.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
