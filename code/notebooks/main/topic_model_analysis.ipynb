{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook fits a topic model to the Sherlock text descriptions and then transformed the recall transcripts with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T17:51:01.902342Z",
     "start_time": "2019-12-01T17:50:57.154117Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hypertools as hyp\n",
    "from os.path import join as opj\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T17:51:02.906541Z",
     "start_time": "2019-12-01T17:51:02.898319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawdir = '../../../data/raw/' \n",
    "datadir = '../../../data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T17:51:25.943816Z",
     "start_time": "2019-12-01T17:51:25.868343Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_text(text):\n",
    "    if isinstance(text, pd.Series):\n",
    "        text = ' '.join(list(text.dropna()))\n",
    "        pattern = \"[^\\w\\s]+\"\n",
    "    else:\n",
    "        pattern = \"[^.\\w\\s]+\"\n",
    "\n",
    "    no_possessive = text.lower().replace(\"'s\", '')\n",
    "    punc_stripped = re.sub(pattern, '', no_possessive)\n",
    "    spaced = ' '.join(punc_stripped.split())\n",
    "    return punc_stripped\n",
    "    \n",
    "def parse_windows(textlist, wsize):\n",
    "    windows = []\n",
    "    w_lengths = []\n",
    "    for ix in range(1, wsize):\n",
    "        start, end = 0, ix\n",
    "        w_lengths.append((start, end))\n",
    "        windows.append(' '.join(textlist[start : end]))\n",
    "\n",
    "    for ix in range(len(textlist)):\n",
    "        start = ix\n",
    "        end = ix + wsize if ix + wsize <= len(textlist) else len(textlist)\n",
    "        w_lengths.append((start, end))\n",
    "        windows.append(' '.join(textlist[start : end]))\n",
    "\n",
    "    return windows, w_lengths\n",
    "\n",
    "\n",
    "def get_video_timepoints(window_spans):\n",
    "    timepoints = []\n",
    "    for first, last in window_spans:\n",
    "        window_onset = video_text.loc[first, 'Start Time (s) ']\n",
    "        window_offset = video_text.loc[last - 1, 'End Time (s) ']\n",
    "        timepoints.append((window_onset + window_offset) / 2)\n",
    "        \n",
    "    return np.array(timepoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T17:51:27.337075Z",
     "start_time": "2019-12-01T17:51:27.333215Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_wsize = 50\n",
    "n_topics = 100\n",
    "recall_wsize = 10\n",
    "\n",
    "# vectorizer parameters\n",
    "vectorizer = {\n",
    "    'model' : 'CountVectorizer', \n",
    "    'params' : {\n",
    "        'stop_words' : 'english'\n",
    "    }\n",
    "}\n",
    "\n",
    "# topic model parameters\n",
    "semantic = {\n",
    "    'model' : 'LatentDirichletAllocation', \n",
    "    'params' : {\n",
    "        'n_components' : n_topics,\n",
    "        'learning_method' : 'batch',\n",
    "        'random_state' : 0,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T17:51:36.799229Z",
     "start_time": "2019-12-01T17:51:36.536798Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_text = pd.read_excel(opj(rawdir, 'Sherlock_Segments_1000_NN_2017.xlsx'))\n",
    "video_text['Scene Segments'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# drop 1s shot & 6s of black screen after end of 1st scan\n",
    "video_text.drop(index=[480, 481], inplace=True)\n",
    "video_text.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# timestamps for 2nd scan restart from 0; add duration of 1st scan to values\n",
    "video_text.loc[480:, 'Start Time (s) ': 'End Time (s) '] += video_text.loc[479, 'End Time (s) ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit topic model to manually-annotated movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T22:57:52.952525Z",
     "start_time": "2019-11-20T22:57:29.462076Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a list of text samples from the scene descriptions / details to train the topic model\n",
    "video = video_text.loc[:,'Scene Details - A Level ':'Words on Screen '].apply(format_text, axis=1).tolist()\n",
    "video_windows, window_bounds = parse_windows(video, video_wsize)\n",
    "\n",
    "# create video model with hypertools\n",
    "video_model = hyp.tools.format_data(video_windows, \n",
    "                                    vectorizer=vectorizer, \n",
    "                                    semantic=semantic, \n",
    "                                    corpus=video_windows)[0]\n",
    "\n",
    "# description are by scene, not TR so stretch the model to be in TRs\n",
    "tr_spans = video_text[['Start Time (TRs, 1.5s)', 'End Time (TRs, 1.5s)']]\n",
    "starts, stops = tr_spans.values.T\n",
    "video_model_TRs = np.empty((1976, 100))\n",
    "\n",
    "xvals = get_video_timepoints(window_bounds)\n",
    "xvals_TR = xvals * 1976 / 2963\n",
    "TR_times = np.arange(1, 1977)\n",
    "interp_func = interp1d(xvals_TR, video_model, axis=0, fill_value='extrapolate')\n",
    "video_model_TRs = interp_func(TR_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T23:09:47.284433Z",
     "start_time": "2019-11-20T23:09:47.225670Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop over subjects\n",
    "recall_w = []\n",
    "for sub in range(1, 18):\n",
    "    # load subject data\n",
    "    transcript_path = opj(rawdir, f'NN{sub} transcript.txt')\n",
    "    with open(transcript_path, 'r', encoding='cp1252') as f:\n",
    "        recall = f.read().replace(b'\\x92'.decode('cp1252'), \"'\").strip()\n",
    "\n",
    "    # create overlapping windows of n sentences\n",
    "    recall_fmt = format_text(recall).split('.')\n",
    "    if not recall_fmt[-1]:\n",
    "        recall_fmt = recall_fmt[:-1]\n",
    "    sub_recall_w = parse_windows(recall_fmt, recall_wsize)[0]\n",
    "    recall_w.append(sub_recall_w)\n",
    "    \n",
    "    # save example participant's recall windows \n",
    "    if sub == 17:\n",
    "        np.save(opj(datadir, 'recall_text.npy'), sub_recall_w)\n",
    "    \n",
    "# create recall models\n",
    "recall_models = hyp.tools.format_data(recall_w, \n",
    "                                      vectorizer=vectorizer, \n",
    "                                      semantic=semantic, \n",
    "                                      corpus=video_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save video model, recall models, and text corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:13:28.479854Z",
     "start_time": "2019-11-18T19:13:28.244526Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(opj(datadir, f'models_t{n_topics}_v{video_wsize}_r{recall_wsize}'), [video_model_TRs, recall_models])\n",
    "np.save(opj(datadir, 'video_text.npy'), video_windows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
