{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook replicates the brain-related analyses. Note: the fMRI data can be downloaded into the data folder from here: https://dataspace.princeton.edu/jspui/handle/88435/dsp01nz8062179"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from os.path import join as opj\n",
    "from nilearn import datasets, surface\n",
    "from nilearn.image import concat_imgs, load_img, new_img_like\n",
    "from scipy.stats import ttest_1samp as ttest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import analysis helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, abspath('../../helpers/'))\n",
    "from analysis_helpers import r2z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths & parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = '../../../data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_perms = [load_img(opj(datadir, f'searchlight_video/perm{perm}.nii.gz')) for perm in range(100)]\n",
    "video_perms = concat_imgs(video_perms).dataobj.astype(np.float64)\n",
    "\n",
    "recall_perms = [load_img(opj(datadir, f'searchlight_recall/perm{perm}.nii.gz')) for perm in range(100)]\n",
    "recall_perms = concat_imgs(recall_perms).dataobj.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_img = load_img(opj(datadir, 'searchlight_video/ref_img.nii.gz'))\n",
    "                   \n",
    "subs = range(1, 18)\n",
    "vid_imgs = []\n",
    "rec_imgs = []\n",
    "for sub in subs:\n",
    "    sub_vdata = np.load(opj(datadir, f'searchlight_video/sub{sub}.npy'), allow_pickle=True)\n",
    "    sub_rdata = np.load(opj(datadir, f'searchlight_recall/sub{sub}.npy'), allow_pickle=True)\n",
    "    vid_img = new_img_like(ref_img, sub_vdata.astype(np.float64))\n",
    "    rec_img = new_img_like(ref_img, sub_rdata.astype(np.float64))\n",
    "    vid_imgs.append(vid_img)\n",
    "    rec_imgs.append(rec_img)\n",
    "    \n",
    "vid_imgs = concat_imgs(vid_imgs)\n",
    "rec_imgs = concat_imgs(rec_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get stats for real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_data = vid_imgs.dataobj.astype(np.float64)\n",
    "video_statmap = ttest(np.moveaxis(r2z(video_data), -1, 0), 0).statistic\n",
    "video_img = new_img_like(ref_img, video_statmap.astype(np.float64))\n",
    "\n",
    "\n",
    "recall_data = rec_imgs.dataobj.astype(np.float64)\n",
    "recall_statmap = ttest(np.moveaxis(r2z(recall_data), -1, 0), 0).statistic\n",
    "recall_img = new_img_like(ref_img, recall_statmap.astype(np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do permutation correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_video = video_img.dataobj.astype(np.float64)\n",
    "real_recall = recall_img.dataobj.astype(np.float64)\n",
    "\n",
    "zval_video = (real_video - np.nanmean(video_perms, axis=3)) / np.nanstd(video_perms, axis=3)\n",
    "pval_video = (real_video[:, :, :, np.newaxis] < video_perms).sum(axis=3) / 100\n",
    "zval_recall = (real_recall - np.nanmean(recall_perms, axis=3)) / np.nanstd(recall_perms, axis=3)\n",
    "pval_recall = (real_recall[:, :, :, np.newaxis] < recall_perms).sum(axis=3) / 100\n",
    "\n",
    "zval_video = np.nan_to_num(zval_video)\n",
    "pval_video = np.nan_to_num(pval_video)\n",
    "zval_recall = np.nan_to_num(zval_recall)\n",
    "pval_recall = np.nan_to_num(pval_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export p-value maps for neurosynth decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns_vid_map = np.copy(pval_video)\n",
    "ns_rec_map = np.copy(pval_recall)\n",
    "\n",
    "# isolate voxels more highly correlated with real trajectories than permuted ones\n",
    "ns_vid_map[zval_video <= 0] = 0\n",
    "ns_rec_map[zval_recall <= 0] = 0\n",
    "\n",
    "ns_vid_map = new_img_like(ref_img, ns_vid_map.astype(np.float64))\n",
    "ns_rec_map = new_img_like(ref_img, ns_rec_map.astype(np.float64))\n",
    "\n",
    "ns_vid_map.to_filename(opj(datadir, 'searchlight_video', 'ns_map_video.nii.gz'))\n",
    "ns_rec_map.to_filename(opj(datadir, 'searchlight_recall', 'ns_map_recall.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zval_video[pval_video > .05] = 0\n",
    "zval_video[zval_video < 0] = 0\n",
    "\n",
    "zval_recall[pval_recall > .05] = 0\n",
    "zval_recall[zval_recall < 0] = 0\n",
    "\n",
    "zmap_video = new_img_like(ref_img, zval_video.astype(np.float64))\n",
    "zmap_recall = new_img_like(ref_img, zval_recall.astype(np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to surface maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsaverage = datasets.fetch_surf_fsaverage(mesh='fsaverage5')\n",
    "vid_texture_pl = surface.vol_to_surf(zmap_video, fsaverage.pial_left)\n",
    "vid_texture_pr = surface.vol_to_surf(zmap_video, fsaverage.pial_right)\n",
    "rec_texture_pl = surface.vol_to_surf(zmap_recall, fsaverage.pial_left)\n",
    "rec_texture_pr = surface.vol_to_surf(zmap_recall, fsaverage.pial_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(opj(datadir, 'searchlight_video', 'video_surface_left.npy'), vid_texture_pl)\n",
    "np.save(opj(datadir, 'searchlight_video', 'video_surface_right.npy'), vid_texture_pr)\n",
    "np.save(opj(datadir, 'searchlight_recall', 'recall_surface_left.npy'), rec_texture_pl)\n",
    "np.save(opj(datadir, 'searchlight_recall', 'recall_surface_right.npy'), rec_texture_pr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
