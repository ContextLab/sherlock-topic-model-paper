{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the event segmentation analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import brainiak.eventseg.event\n",
    "import hypertools as hyp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "import pickle\n",
    "\n",
    "def score_model(mcorr, model, k, s):\n",
    "    i1, i2 = np.where(np.round(model.segments_[0])==1)\n",
    "    w = np.zeros_like(model.segments_[0])\n",
    "    w[i1,i2] = 1\n",
    "    w = np.dot(w, w.T).astype(bool)\n",
    "    return mcorr[w].mean()/mcorr[~w].mean() - k/s\n",
    "    \n",
    "def reduce_model(m, ev):\n",
    "    \"\"\"Reduce a model based on event labels\"\"\"\n",
    "    w = (np.round(ev.segments_[0])==1).astype(bool)\n",
    "    return np.array([m[wi, :].mean(0) for wi in w.T])\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../../../data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_model, recall_models = np.load(datadir+'models_t100_v50_r10.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal k for video model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=[]\n",
    "corrmat = np.corrcoef(video_model)\n",
    "for i, events in enumerate(range(1, 51)):\n",
    "    ev = event.EventSegment(events)\n",
    "    ev.fit(movie_model)\n",
    "    t = np.round(ev.segments_[0]).astype(int)\n",
    "    mask = np.sum(list(map(lambda x: np.outer(x, x), t.T)), 0).astype(bool)\n",
    "    within = corrmat[mask].mean()\n",
    "    across = corrmat[~mask].mean()\n",
    "    m.append((within, across, within/across))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the within and across correlation values as a function of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(map(lambda x: x[0], m)), label='Within-event correlation')\n",
    "plt.plot(list(map(lambda x: x[1], m)), label='Across-event correlation')\n",
    "plt.legend()\n",
    "plt.ylabel('Correlation')\n",
    "plt.xlabel('Number of events (k)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the ratio of within/across ratio as a function of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=list(map(lambda x: x[0]/(x[1]-min(m[1])), m))[1:]\n",
    "t/=np.max(t)\n",
    "for i, v in enumerate(t):\n",
    "    t[i]-=i/250\n",
    "plt.plot(t, label='Within-event correlation')\n",
    "plt.ylabel('abs(within/across) ratio')\n",
    "plt.xlabel('Number of events (k)')\n",
    "maxk_video = np.argmax(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit event segmentation model to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = brainiak.eventseg.event.EventSegment(maxk_video)\n",
    "ev.fit(video_model)\n",
    "video_events = reduce_model(video_model, ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/video_eventseg_model', 'wb') as f:\n",
    "#     pickle.dump(ev, f)\n",
    "# np.save('../data/video_events', video_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get video event times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_event_times = []\n",
    "for s in ev.segments_[0].T:\n",
    "    tp = np.where(np.round(s)==1)[0]\n",
    "    video_event_times.append((tp[0], tp[-1]))\n",
    "np.save(datadir+'video_event_times', video_event_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit event segmentation model to recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = list(range(2, 30))\n",
    "maxk = []\n",
    "for i, sub in enumerate(recall_models):\n",
    "    mcorr = np.corrcoef(sub)\n",
    "    cs = []\n",
    "    for k in ks:\n",
    "        ev = brainiak.eventseg.event.EventSegment(k)\n",
    "        ev.fit(sub)\n",
    "        i1, i2 = np.where(np.round(ev.segments_[0])==1)\n",
    "        w = np.zeros_like(ev.segments_[0])\n",
    "        w[i1,i2] = 1\n",
    "        w = np.dot(w, w.T).astype(bool)\n",
    "        c = mcorr[w].mean()/mcorr[~w].mean() - k/50\n",
    "        cs.append(c)\n",
    "    m = ks[np.argmax(cs)]\n",
    "    maxk.append(m)\n",
    "    print(i, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model to recall using best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_events = []\n",
    "recall_event_times = []\n",
    "recall_eventseg_models = []\n",
    "for i, k in enumerate(maxk):\n",
    "    ev = brainiak.eventseg.event.EventSegment(k)\n",
    "    ev.fit(recall_models[i])\n",
    "    m = reduce_model(recall_models[i], ev)\n",
    "    recall_events.append(m)\n",
    "    recall_times = []\n",
    "    for s in ev.segments_[0].T:\n",
    "        tp = np.where(np.round(s)==1)[0]\n",
    "        recall_times.append((tp[0], tp[-1]))\n",
    "    recall_event_times.append(recall_times)\n",
    "    recall_eventseg_models.append(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create average recall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = np.array([np.argmax(1 - cdist(video_events, r, 'correlation'), 0) for r in recall_events])\n",
    "avg_recalls = [[] for _ in video_events]\n",
    "for match, r in zip(matches, recall_events):\n",
    "    for i, m in enumerate(match):\n",
    "        avg_recalls[m].append(r[i,:])\n",
    "avg_recall_events = np.array(list(map(lambda r: np.mean(r, 0) if len(r)>0 else np.zeros((100,)), avg_recalls)))\n",
    "# avg_recall_events = np.array([a.reshape(100,) for a in avg_recall_events if a.shape==(100,)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 2D embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "embeddings = hyp.reduce(recall_events+[video_events]+[avg_recall_events], reduce='UMAP', ndims=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(datadir+'avg_recall_events', avg_recall_events)\n",
    "# np.save(datadir+'embeddings', [embeddings[:-2], embeddings[-2], embeddings[:-1]])\n",
    "# np.save(datadir+'labels', matches)\n",
    "# np.save(datadir+'recall_events', recall_events)\n",
    "# np.save(datadir+'recall_event_times', recall_event_times)\n",
    "# with open(datadir+'recall_eventseg_models', 'wb') as f:\n",
    "#     pickle.dump(recall_eventseg_models, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
