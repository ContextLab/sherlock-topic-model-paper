{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the event segmentation analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:14:56.348114Z",
     "start_time": "2019-11-18T19:14:52.408306Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import brainiak.eventseg.event as event\n",
    "import hypertools as hyp\n",
    "from os.path import abspath, join as opj\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import wasserstein_distance, pearsonr\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import analysis helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, abspath('../../helpers/'))\n",
    "from analysis_helpers import HAND_REC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_model(m, ev):\n",
    "    \"\"\"Reduce a model based on event labels\"\"\"\n",
    "    w = (np.round(ev.segments_[0])==1).astype(bool)\n",
    "    return np.array([m[wi, :].mean(0) for wi in w.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths & params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:14:56.360497Z",
     "start_time": "2019-11-18T19:14:56.356608Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = '../../../data/processed/'\n",
    "figdir = '../../../paper/figs/'\n",
    "\n",
    "sns.set_context('paper')\n",
    "mpl.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:14:56.708085Z",
     "start_time": "2019-11-18T19:14:56.626121Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_model, recall_models = np.load(opj(datadir, 'models_t100_v50_r10.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal k for video model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:23:08.172578Z",
     "start_time": "2019-11-18T19:15:01.623081Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nEvents = np.arange(2,51)\n",
    "wd = np.zeros(len(nEvents))\n",
    "corrmat = np.corrcoef(video_model)\n",
    "\n",
    "for i, events in enumerate(nEvents):\n",
    "    print(f'fitting with {events} events...', end='\\r')\n",
    "    ev = event.EventSegment(events)\n",
    "    ev.fit(video_model)\n",
    "    \n",
    "    i1, i2 = np.where(np.round(ev.segments_[0])==1)\n",
    "    w = np.zeros_like(ev.segments_[0])\n",
    "    w[i1,i2] = 1\n",
    "    mask = np.dot(w, w.T).astype(bool)\n",
    "\n",
    "    # Create mask such that the maximum temporal distance for \n",
    "    # within and across correlations is the same\n",
    "    local_mask = np.zeros(mask.shape, dtype=bool)\n",
    "    for k in range(mask.shape[0]):\n",
    "        if ~np.any(np.diag(mask, k)):\n",
    "            break\n",
    "        local_mask[np.diag(np.ones(local_mask.shape[0]-k, dtype=bool), k)] = True\n",
    "    within_vals = np.reshape(corrmat[mask*local_mask], -1, 1) \n",
    "    across_vals = np.reshape(corrmat[~mask*local_mask], -1, 1)\n",
    "    wd[i] = wasserstein_distance(within_vals, across_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Wasserstein distance as a function of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T03:07:22.971473Z",
     "start_time": "2019-11-20T03:07:22.689824Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(nEvents, wd)\n",
    "maxk_video = nEvents[np.argmax(wd)]\n",
    "plt.ylabel('Wasserstein distance')\n",
    "plt.xlabel('Number of events ($K$)')\n",
    "plt.title(f'Video: optimal $K$ = {maxk_video}')\n",
    "plt.savefig(opj(figdir, 'k_optimization_video.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit event segmentation model to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T22:41:15.710154Z",
     "start_time": "2019-11-18T22:40:56.130977Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ev = event.EventSegment(maxk_video)\n",
    "ev.fit(video_model)\n",
    "video_events = reduce_model(video_model, ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:23:21.149742Z",
     "start_time": "2019-11-18T19:23:21.145386Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(opj(datadir, 'video_events'), video_events)\n",
    "with open(opj(datadir, 'video_eventseg_model'), 'wb') as f:\n",
    "    pickle.dump(ev, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get video event times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:23:21.158670Z",
     "start_time": "2019-11-18T19:23:21.151972Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_event_times = []\n",
    "for s in ev.segments_[0].T:\n",
    "    tp = np.where(np.round(s)==1)[0]\n",
    "    video_event_times.append((tp[0], tp[-1]))\n",
    "np.save(opj(datadir, 'video_event_times'), video_event_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit event segmentation model to recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T21:59:19.644332Z",
     "start_time": "2019-11-18T19:23:21.160835Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks = list(range(2, 51))\n",
    "scores = []\n",
    "for i, sub in enumerate(recall_models):\n",
    "    mcorr = np.corrcoef(sub)\n",
    "    cs = []\n",
    "    for k in ks:\n",
    "        print(f'\\tfitting subject {i + 1} with {k} events...', end='\\r')\n",
    "        ev = event.EventSegment(k)\n",
    "        ev.fit(sub)\n",
    "        i1, i2 = np.where(np.round(ev.segments_[0])==1)\n",
    "        w = np.zeros_like(ev.segments_[0])\n",
    "        w[i1,i2] = 1\n",
    "        mask = np.dot(w, w.T).astype(bool)\n",
    "        \n",
    "        # Create mask such that the maximum temporal distance for # within and across correlations is the same\n",
    "        local_mask = np.zeros(mask.shape, dtype=bool)\n",
    "        for m in range(mask.shape[0]):\n",
    "            if ~np.any(np.diag(mask, m)):\n",
    "                break\n",
    "            local_mask[np.diag(np.ones(local_mask.shape[0]-m, dtype=bool), m)] = True\n",
    "        within_vals = np.reshape(mcorr[mask*local_mask], -1, 1) \n",
    "        across_vals = np.reshape(mcorr[~mask*local_mask], -1, 1)\n",
    "        cs.append(wasserstein_distance(within_vals, across_vals))\n",
    "    scores.append(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T21:59:20.899479Z",
     "start_time": "2019-11-18T21:59:19.663689Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "fig, axarr = plt.subplots(nrows=5, ncols=4, sharey=True)\n",
    "fig.set_size_inches(20,20)\n",
    "axarr = axarr.flatten()\n",
    "\n",
    "ks = list(range(2, 51))\n",
    "maxk = []\n",
    "\n",
    "for sub, cs in enumerate(scores):\n",
    "    opt_k = ks[np.argmax(cs)]\n",
    "    maxk.append(opt_k)\n",
    "    \n",
    "    axarr[sub].plot(ks, cs)\n",
    "    axarr[sub].set_xticks(list(range(0, 51, 10)))\n",
    "    axarr[sub].set_xlim(0, 51)\n",
    "    axarr[sub].set_ylim(.1, .6)\n",
    "    \n",
    "    if not sub % 4:\n",
    "        axarr[sub].set_ylabel('Wasserstein distance', fontsize=16)\n",
    "        axarr[sub].tick_params(axis='y', labelsize=14)\n",
    "    else:\n",
    "        axarr[sub].set_ylabel('')\n",
    "\n",
    "    if sub >= 13:\n",
    "        axarr[sub].set_xlabel('Number of events ($K$)', fontsize=16)\n",
    "        axarr[sub].tick_params(axis='x', labelsize=14)\n",
    "    else:\n",
    "        axarr[sub].set_xlabel('')\n",
    "        axarr[sub].set_xticklabels([])\n",
    "        \n",
    "    axarr[sub].set_title(f'P{sub + 1}: optimal $K$ = {opt_k}', fontsize=16)\n",
    "    \n",
    "axarr[-3].axis('off')\n",
    "axarr[-2].axis('off')\n",
    "axarr[-1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust()\n",
    "plt.savefig(opj(figdir, 'k_optimization_recall.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T22:03:01.693913Z",
     "start_time": "2019-11-18T22:03:01.689985Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot(HAND_REC, maxk, kind = 'reg', order = 1, space=0, stat_func=pearsonr)\n",
    "plt.xlabel('Hand-annotated memory performance')\n",
    "plt.ylabel('Number of events ($K$)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model to recall using best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T22:07:09.104190Z",
     "start_time": "2019-11-18T22:03:57.006317Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_events = []\n",
    "recall_event_times = []\n",
    "recall_eventseg_models = []\n",
    "for i, k in enumerate(maxk):\n",
    "    ev = event.EventSegment(k)\n",
    "    ev.fit(recall_models[i])\n",
    "    m = reduce_model(recall_models[i], ev)\n",
    "    recall_events.append(m)\n",
    "    recall_times = []\n",
    "    for s in ev.segments_[0].T:\n",
    "        tp = np.where(np.round(s)==1)[0]\n",
    "        recall_times.append((tp[0], tp[-1]))\n",
    "    recall_event_times.append(recall_times)\n",
    "    recall_eventseg_models.append(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create average recall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T22:07:09.115991Z",
     "start_time": "2019-11-18T22:07:09.106182Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matches = np.array([np.argmax(1 - cdist(video_events, r, 'correlation'), 0) for r in recall_events])\n",
    "avg_recalls = [[] for _ in video_events]\n",
    "for match, r in zip(matches, recall_events):\n",
    "    for i, m in enumerate(match):\n",
    "        avg_recalls[m].append(r[i,:])\n",
    "avg_recall_events = np.array(list(map(lambda r: np.mean(r, 0) if len(r)>0 else np.zeros((100,)), avg_recalls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T22:07:09.135397Z",
     "start_time": "2019-11-18T22:07:09.118944Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(opj(datadir, 'avg_recall_events'), avg_recall_events)\n",
    "np.save(opj(datadir, 'labels'), matches)\n",
    "np.save(opj(datadir, 'recall_events'), recall_events)\n",
    "np.save(opj(datadir, 'recall_event_times'), recall_event_times)\n",
    "with open(opj(datadir, 'recall_eventseg_models'), 'wb') as f:\n",
    "    pickle.dump(recall_eventseg_models, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
